{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, command, Input\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create connection to Azure ML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "default_azure_credential = DefaultAzureCredential()\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=default_azure_credential,\n",
    "    subscription_id=\"YOUR SUBSCRIPTION\",\n",
    "    resource_group_name=\"YOUR RESOURCE GROUP\",\n",
    "    workspace_name=\"YOUR WORKSPACE NAME\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Register model (use existing score.py in the app python module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': 'Fit', 'description': 'Fit app module', 'tags': {}, 'properties': {}, 'id': '/subscriptions/54108101-44be-4e65-a655-ea14694b0a64/resourceGroups/test2-rg/providers/Microsoft.MachineLearningServices/workspaces/versioning/models/Fit/versions/1', 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f35fc476f80>, 'serialize': <msrest.serialization.Serializer object at 0x7f36089d3f70>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/54108101-44be-4e65-a655-ea14694b0a64/resourceGroups/test2-rg/workspaces/versioning/datastores/workspaceblobstore/paths/LocalUpload/5b6d0714cd2c84103fd5241824947d2b/app', 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_model = Model(\n",
    "    path=\"../app/\",\n",
    "    type=\"custom_model\",\n",
    "    name=\"Fit\",\n",
    "    description=\"Fit app module\"\n",
    ")\n",
    "ml_client.models.create_or_update(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model as REST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating local endpoint (fit-local) ."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint fit provisioning state: Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done (0m 5s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': 'Failed', 'scoring_uri': None, 'swagger_uri': None, 'name': 'fit-local', 'description': 'local endpoint', 'tags': {}, 'properties': {}, 'id': None, 'base_path': './', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7ff03c228fd0>, 'auth_mode': 'key', 'location': 'local', 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=\"Fit\",\n",
    "    description=\"Versioned python endpoint for FIT\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\n",
    "        \"function\": \"fit\",\n",
    "        \"model_type\": \"sklearn.LinearRegression\",\n",
    "    },\n",
    ")\n",
    "\n",
    "endpoint = ml_client.begin_create_or_update(endpoint)\n",
    "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")\n",
    "\n",
    "#Create also local endpoint\n",
    "local_endpoint = ManagedOnlineEndpoint(\n",
    "    name=\"fit-local\", description=\"local endpoint\"\n",
    ")\n",
    "\n",
    "ml_client.online_endpoints.begin_create_or_update(local_endpoint, local=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating local deployment (fit-local / local-v100) \n",
      "Building Docker image from Dockerfile.\n",
      "Step 1/6 : FROM mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:20220516.v3\n",
      " ---> 2ba524631f05\n",
      "Step 2/6 : RUN mkdir -p /var/azureml-app/\n",
      " ---> Using cache\n",
      " ---> cd9d8004f482\n",
      "Step 3/6 : WORKDIR /var/azureml-app/\n",
      " ---> Using cache\n",
      " ---> 9833df5c499b\n",
      "Step 4/6 : COPY conda.yml /var/azureml-app/\n",
      " ---> Using cache\n",
      " ---> 411cf2c805fe\n",
      "Step 5/6 : RUN conda env create -n inf-conda-env --file conda.yml\n",
      " ---> Using cache\n",
      " ---> a8e14e67f1d3\n",
      "Step 6/6 : CMD [\"conda\", \"run\", \"--no-capture-output\", \"-n\", \"inf-conda-env\", \"runsvdir\", \"/var/runit\"]\n",
      " ---> Using cache\n",
      " ---> dcd99470c340\n",
      "Successfully built dcd99470c340\n",
      "Successfully tagged fit-local:local-v100\n",
      "\n",
      "Starting up endpoint...Done (0m 20s)\n"
     ]
    }
   ],
   "source": [
    "#Test local deploy first\n",
    "\n",
    "#Use local files as model on local deployment\n",
    "local_model = Model(path=\"../app/\")\n",
    "\n",
    "env = Environment(\n",
    "    conda_file=\"../conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/minimal-ubuntu18.04-py37-cpu-inference:20220516.v3\",\n",
    ")\n",
    "\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"local-v100\",\n",
    "    endpoint_name=local_endpoint.name,\n",
    "    model=local_model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"../.\", scoring_script=\"score.py\"\n",
    "    )\n",
    ")\n",
    "\n",
    "#Test local deployment first\n",
    "\n",
    "deployment = ml_client.begin_create_or_update(deployment, local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"2022-08-23T11:34:02,566123961+00:00 | gunicorn/run | ###############################################\\r\\n2022-08-23T11:34:02,567674790+00:00 | gunicorn/run | Dynamic Python Package Installation\\r\\n2022-08-23T11:34:02,569201718+00:00 | gunicorn/run | ###############################################\\r\\n2022-08-23T11:34:02,571163054+00:00 | gunicorn/run | \\r\\n2022-08-23T11:34:02,573051289+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\\r\\n2022-08-23T11:34:02,575217729+00:00 | gunicorn/run | \\r\\n2022-08-23T11:34:02,577143964+00:00 | gunicorn/run | ###############################################\\r\\n2022-08-23T11:34:02,578974598+00:00 | gunicorn/run | AzureML Inference Server\\r\\n2022-08-23T11:34:02,581206439+00:00 | gunicorn/run | ###############################################\\r\\n2022-08-23T11:34:02,582738367+00:00 | gunicorn/run | \\r\\n2022-08-23T11:34:02,613363932+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\r\\n\\r\\nAzure ML Inferencing HTTP server v0.4.14\\r\\n\\r\\n\\r\\nServer Settings\\r\\n---------------\\r\\nEntry Script Name: score.py\\r\\nModel Directory: /var/azureml-app/azureml-models//c9020d17eba2e1d4d0897d214dbeb2c4/1\\r\\nWorker Count: 1\\r\\nWorker Timeout (seconds): 300\\r\\nServer Port: 31311\\r\\nApplication Insights Enabled: false\\r\\nApplication Insights Key: None\\r\\n\\r\\n\\r\\nServer Routes\\r\\n---------------\\r\\nLiveness Probe: GET   127.0.0.1:31311/\\r\\nScore:          POST  127.0.0.1:31311/score\\r\\n\\r\\nStarting gunicorn 20.1.0\\r\\nListening at: http://0.0.0.0:31311 (28)\\r\\nUsing worker: sync\\r\\nBooting worker with pid: 69\\r\\nInitializing logger\\r\\n2022-08-23 11:34:03,707 | root | INFO | Starting up app insights client\\r\\nlogging socket was found. logging is available.\\r\\nlogging socket was found. logging is available.\\r\\n2022-08-23 11:34:03,726 | root | INFO | Starting up request id generator\\r\\n2022-08-23 11:34:03,726 | root | INFO | Starting up app insight hooks\\r\\n2022-08-23 11:34:03,726 | root | INFO | Invoking user's init function\\r\\nModel dir already existed, since this is just a demo not really reacting to it...\\r\\nno request id,Model dir already existed, since this is just a demo not really reacting to it...\\r\\n\\r\\nInit complete\\r\\n2022-08-23 11:34:03,738 | root | INFO | Users's init has completed successfully\\r\\n2022-08-23 11:34:03,742 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\\r\\n2022-08-23 11:34:03,742 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\\r\\n2022-08-23 11:34:03,745 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\r\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify local endpoints\n",
    "ml_client.online_endpoints.get(name=\"fit-local\", local=True)\n",
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"local-v100\", endpoint_name=\"fit-local\", local=True, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint fit exists\n",
      "\u001b[32mUploading python-rest-versioning (0.13 MBs): 100%|██████████| 134042/134042 [00:00<00:00, 269450.43it/s]\n",
      "\u001b[39m\n",
      "\n",
      "Creating/updating online deployment v100 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done (12m 23s)\n"
     ]
    }
   ],
   "source": [
    "#Deploy to Azure\n",
    "\n",
    "#Get the latest version of FIT from model repository\n",
    "latest_model_version = max(\n",
    "    [int(m.version) for m in ml_client.models.list(name=\"Fit\")]\n",
    ")\n",
    "model = ml_client.models.get(name=\"Fit\", version=latest_model_version)\n",
    "\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"v100\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"../.\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_type=\"Standard_DS1_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "deployment = ml_client.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operate endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Instance status:\\nSystemSetup: Succeeded\\nUserContainerImagePull: Succeeded\\nModelDownload: Succeeded\\nUserContainerStart: Succeeded\\n\\nContainer events:\\nKind: Pod, Name: Downloading, Type: Normal, Time: 2022-08-23T12:03:52.586592Z, Message: Start downloading models\\nKind: Pod, Name: Pulling, Type: Normal, Time: 2022-08-23T12:03:52.760815Z, Message: Start pulling container image\\nKind: Pod, Name: Pulled, Type: Normal, Time: 2022-08-23T12:04:36.592985Z, Message: Container image is pulled successfully\\nKind: Pod, Name: Downloaded, Type: Normal, Time: 2022-08-23T12:04:36.592985Z, Message: Models are downloaded successfully\\nKind: Pod, Name: Created, Type: Normal, Time: 2022-08-23T12:04:36.85377Z, Message: Created container inference-server\\nKind: Pod, Name: Started, Type: Normal, Time: 2022-08-23T12:04:37.119539Z, Message: Started container inference-server\\nKind: Pod, Name: ContainerReady, Type: Normal, Time: 2022-08-23T12:04:51.355475525Z, Message: Container is ready\\n\\nContainer logs:\\nopencensus==0.11.0\\nopencensus-context==0.1.3\\nopencensus-ext-azure==1.1.7\\npackaging==21.3\\nparamiko==2.11.0\\npathspec==0.9.0\\npkginfo==1.8.3\\nportalocker==2.5.1\\nprotobuf==4.21.5\\npsutil==5.9.1\\npyarrow==3.0.0\\npyasn1==0.4.8\\npyasn1-modules==0.2.8\\npycparser==2.21\\nPygments==2.13.0\\nPyJWT==2.4.0\\nPyNaCl==1.5.0\\npyOpenSSL==21.0.0\\npyparsing==3.0.9\\nPySocks==1.7.1\\npython-dateutil==2.8.2\\npytz==2022.2.1\\nPyYAML==6.0\\nrequests==2.28.1\\nrequests-oauthlib==1.3.1\\nrsa==4.9\\nscikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1630910536896/work\\nscipy @ file:///home/conda/feedstock_root/build_artifacts/scipy_1628206376058/work\\nSecretStorage==3.3.3\\nsix==1.16.0\\ntabulate==0.8.10\\nthreadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1643647933166/work\\ntyping_extensions==4.3.0\\nurllib3==1.26.7\\nwebsocket-client==1.3.3\\nWerkzeug==1.0.1\\nwrapt==1.12.1\\nzipp==3.8.1\\n\\n2022-08-23T12:04:39,276627616+00:00 | gunicorn/run | \\n2022-08-23T12:04:39,284362630+00:00 | gunicorn/run | Entry script directory: /var/azureml-app/python-rest-versioning/.\\n2022-08-23T12:04:39,286597734+00:00 | gunicorn/run | \\n2022-08-23T12:04:39,292084443+00:00 | gunicorn/run | ###############################################\\n2022-08-23T12:04:39,309490773+00:00 | gunicorn/run | Dynamic Python Package Installation\\n2022-08-23T12:04:39,319094089+00:00 | gunicorn/run | ###############################################\\n2022-08-23T12:04:39,324317998+00:00 | gunicorn/run | \\n2022-08-23T12:04:39,326663602+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\\n2022-08-23T12:04:39,332951213+00:00 | gunicorn/run | \\n2022-08-23T12:04:39,336476819+00:00 | gunicorn/run | ###############################################\\n2022-08-23T12:04:39,340537426+00:00 | gunicorn/run | AzureML Inference Server\\n2022-08-23T12:04:39,345024534+00:00 | gunicorn/run | ###############################################\\n2022-08-23T12:04:39,350527743+00:00 | gunicorn/run | \\n2022-08-23T12:04:39,365481769+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\n\\nAzure ML Inferencing HTTP server v0.4.14\\n\\n\\nServer Settings\\n---------------\\nEntry Script Name: score.py\\nModel Directory: /var/azureml-app/azureml-models/Fit/2\\nWorker Count: 1\\nWorker Timeout (seconds): 300\\nServer Port: 31311\\nApplication Insights Enabled: false\\nApplication Insights Key: None\\n\\n\\nServer Routes\\n---------------\\nLiveness Probe: GET   127.0.0.1:31311/\\nScore:          POST  127.0.0.1:31311/score\\n\\nStarting gunicorn 20.1.0\\nListening at: http://0.0.0.0:31311 (10)\\nUsing worker: sync\\nBooting worker with pid: 52\\nInitializing logger\\n2022-08-23 12:04:42,047 | root | INFO | Starting up app insights client\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2022-08-23 12:04:42,048 | root | INFO | Starting up request id generator\\n2022-08-23 12:04:42,048 | root | INFO | Starting up app insight hooks\\n2022-08-23 12:04:42,049 | root | INFO | Invoking user\\'s init function\\nModel dir already existed, since this is just a demo not really reacting to it...\\nno request id,Model dir already existed, since this is just a demo not really reacting to it...\\n\\nInit complete\\n2022-08-23 12:04:42,050 | root | INFO | Users\\'s init has completed successfully\\n2022-08-23 12:04:42,051 | root | INFO | Skipping middleware: dbg_model_info as it\\'s not enabled.\\n2022-08-23 12:04:42,052 | root | INFO | Skipping middleware: dbg_resource_usage as it\\'s not enabled.\\n2022-08-23 12:04:42,053 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\n2022-08-23 14:18:36,436 | root | INFO | Swagger file not present\\n2022-08-23 14:18:36,437 | root | INFO | 404\\n127.0.0.1 - - [23/Aug/2022:14:18:36 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"-\"\\n2022-08-23 14:18:38,278 | root | INFO | Scoring Timer is set to 3600.0 seconds\\nRequest received\\nRequest processed\\n2022-08-23 14:18:38,284 | root | INFO | 200\\n127.0.0.1 - - [23/Aug/2022:14:18:38 +0000] \"POST /score?verbose=true HTTP/1.0\" 200 19768 \"-\" \"-\"\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=\"v100\", endpoint_name=\"fit\",  lines=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
